{
  "head": {
    "title": "Data Encoding Techniques",
    "subtitle": "Testing different data encoding techniques for speed and compression.",
    "date": 1579992651,
    "link": "encoding-with-avro-json-csv-protobuf-base64-in-java",
    "description": "Many people default to simple CSV or JSON to encode data to transfer between apps. But, there are much faster and more efficient approaches like Protobuf and Avro.",
    "image": "image/generic/network.jpg",
    "markdown": true,
    "tags": [
      "avro",
      "json",
      "csv",
      "base64",
      "protobuf",
      "java",
      "maven",
      "apache",
      "google",
      "compression",
      "programming"
    ]
  },
  "contents": "<p>So, I've always been a fan of big data. I do it as my full time job. And trust me, it costs a lot of money to move data around. The more data you have, the more it costs.</p>\n<p>When comparing encoding techniques, there may only be a few kilobytes of difference between the two. But if you have billions of encoded readings, even a fraction of a fraction of bytes saved can save thousands of dollars.</p>\n<p><a href=\"https://github.com/jackmead515?tab=repositories\" rel=\"noopener noreferrer\" target=\"_blank\">Serialization Methods Github Source Code</a></p>\n<pre><code class=\"bash language-bash\">20,000 strings at 20 characters\n20,000 numbers at 32 bits\n\n==| CSV |==\nData Size: 1024302 bytes\nBase64 Size: 1365736 bytes\nEncode Time: 4.538122835 ms\nParse Time: 9.893573074999999 ms\n\n==| JSON |==\nData Size: 1268814 bytes\nBase64 Size: 1691752 bytes\nEncode Time: 8.921927827 ms\nParse Time: 8.213622645 ms\n\n==| ProtoBuf |==\nData Size: 936944 bytes\nBase64 Size: 1249260 bytes\nEncode Time: 5.467107863 ms\nParse Time: 1.2513737409999999 ms\n\n==| Avro |==\nData Size: 847351 bytes\nBase64 Size: 1129804 bytes\nEncode Time: 4.372638659 ms\nParse Time: 2.6514886630000003 ms\n</code></pre>\n<p>So what kind of techniques are out there? What do the professionals recommend? For starters, there is the famous JSON</p>\n<h2 id=\"json\">JSON</h2>\n<p>JSON is really cool because it's extremely human readable. Many configuration files, embedded data, and records are stored in this format. In fact, this blog your reading is actually written and stored as JSON in my github repo. Since I have a disk quota, at the time of writing this, at 100GB (hard limit) I don't have anything to worry about and could stored hundreds of blog posts on there.</p>\n<p>But, JSON is the most expensive, in terms of size, in my list. In the link above, I stored 20,000 strings of 20 characters long, and 20,000 integers (32 bits) in a simple JSON schema. This resulted in 1269 KB of data. Not bad! But we can do much better.</p>\n<h2 id=\"csv\">CSV</h2>\n<p>CSV is another very popular human readable encoding format. It is the prefered format for spreadsheets, tables, and even AI datasets as it can easily store row x column based data.</p>\n<p>And it's fast! Using the same strings and numbers as above, The encoding time was HALF of JSON's encoding time. Woah! Additionally, it's also lighter of on the disk space coming in at around 1024 KB. But is there anything better? Oh heck yeah…</p>\n<h2 id=\"protobuf\">Protobuf</h2>\n<p>This is an insanely cool format released by the Google team. But, it's a little different then your traditional formats like JSON, CSV, or XML. The main difference is that your data is stored seperately from it's own schema. Your schema is actually stored as a seperate 'proto' file. An example is seen below.</p>\n<pre><code class=\"rust language-rust\">message Wrapper {\n  repeated string name = 1;\n  repeated int32 number = 2;\n}\n</code></pre>\n<p>Obviously the schema can get much more complicated, but, you write your schema in this sudo language and then encode the data with it. In my example, I stored the strings and numbers with this schema which resulted in only 936.9KB. Funny thing is that it was actually slower at encoding the data then CSV, but faster at parsing it then any other format listed here! The average parse time was just 1.2 miliseconds!! Blazing fast!</p>\n<p>Is there something better than this? It would be hard to imagine, but, there certainly is. Unfortunately, it's an Apache creation. Yuck…</p>\n<h2 id=\"avro\">Avro</h2>\n<p>Taking the same concept as Protobuf, Avro has a schema file written in JSON and then encodes the data with that. Admittedly, it beats all other encoding methods at everything (only losing to Protobuf in parsing time just slightly).</p>\n<pre><code class=\"javascript language-javascript\">{\n    \"namespace\": \"\",\n    \"name\": \"AvroSample\",\n    \"type\": \"record\",\n    \"fields\": [\n        {\n            \"name\": \"name\",\n            \"type\": {\n                \"name\": \"nameType\",\n                \"type\": \"array\",\n                \"items\": \"string\"\n            }\n        },\n        {\n            \"name\": \"number\",\n            \"type\": {\n                \"name\": \"numberType\",\n                \"type\": \"array\",\n                \"items\": \"int\"\n            }\n        }\n    ]\n}\n</code></pre>\n<p>This schema takes those strings and numbers and turns it into just 847 KB in 4.3 milliseconds. And it hasn't even been compressed yet!</p>\n<h2 id=\"overview\">Overview</h2>\n<p>When I chose to use JSON for my blogs, I did it knowing that it was slow and heavy on disk. But I didn't mind because in the end it's still fast enough to make my blog load really fast. Would it be cool to use something even faster and more compact? Sure of course! But it's not super necessary. However, I also make this educated choices whenever I make a new product. And now, with these comparisons, you can too.</p>\n<p>Giving tutorials over Protobuf and Avro would be way to boring and take a long time to make complete. Besides, there is already great documentation in addition to the source code I built in Java. So instead, I suggest reading these links below. These are all tools and tutorials I have used to learn the schema and how to start building your own big data applications!</p>\n<table>\n<thead>\n<tr>\n<th>Protobuf</th>\n<th>Avro</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><a href=\"https://developers.google.com/protocol-buffers/docs/proto3\" rel=\"noopener noreferrer\" target=\"_blank\">Documentation on V3 Schema</a></td>\n<td><a href=\"https://avro.apache.org/docs/1.7.6/spec.html\" rel=\"noopener noreferrer\" target=\"_blank\">Schema Specification</a></td>\n</tr>\n<tr>\n<td><a href=\"https://www.npmjs.com/package/protobufjs\" rel=\"noopener noreferrer\" target=\"_blank\">Node.js NPM: protobufjs</a></td>\n<td><a href=\"https://www.npmjs.com/package/avsc\" rel=\"noopener noreferrer\" target=\"_blank\">Node.js NPM: avsc</a></td>\n</tr>\n<tr>\n<td><a href=\"https://mvnrepository.com/artifact/com.google.protobuf/protobuf-java\" rel=\"noopener noreferrer\" target=\"_blank\">Java Maven: com.google.protobuf</a></td>\n<td><a href=\"https://mvnrepository.com/artifact/org.apache.avro/avro\" rel=\"noopener noreferrer\" target=\"_blank\">Java Maven: org.apache.avro</a></td>\n</tr>\n<tr>\n<td><a href=\"https://crates.io/crates/protobuf\" rel=\"noopener noreferrer\" target=\"_blank\">Rust Crates: protobuf</a></td>\n<td><a href=\"https://crates.io/crates/avro-rs\" rel=\"noopener noreferrer\" target=\"_blank\">Rust Crates: avro-rs</a></td>\n</tr>\n</tbody>\n</table>\n<p>If you enjoyed this content, let me know in the comments below. If you'd like to see more or learn more, don't be afraid to ask!</p>"
}