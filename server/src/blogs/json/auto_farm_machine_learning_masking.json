{
  "head": {
    "title": "Extracting Colored Masks From Auto Farm Images",
    "subtitle": "Learn to extract colored pixels out of images and plot them using OpenCV and Matplotlib",
    "date": 1606089409,
    "link": "auto-farm-machine-learning-opencv-matplotlib-colored-masks",
    "description": "Follow along with me as I explore the image data of my basil experiment using machine learning and opencv techniques to extract the green masks of the plants",
    "image": "image/autofarm/mask.png",
    "markdown": true,
    "tags": [
      "programming",
      "electronics",
      "c++",
      "c",
      "rust",
      "python",
      "javascript",
      "postgres",
      "grafana",
      "raspberry",
      "pi",
      "arduino",
      "opencv",
      "linux",
      "docker",
      "systemd"
    ]
  },
  "contents": "<p>So far I've made some facinating discoveries. And I want to share them with you while also teaching you a few tricks and tips on how to use matplotlib and opencv. It's pretty exciting stuff if your a nerd like me.</p>\n<p><details open>\n<summary>Green Pixel Experiment Results</summary>\n<br>\n    <img src=\"https://www.speblog.org/image/autofarm/full_green_graph_back.png\">\n</details></p>\n<p>What your seeing is all the datapoints corresponding to the green pixels within the different\nimage classes. Unfortunately, for this initial experiment, I ran into a camera problem. The crappy\nUSB web camera I had was only rated at 720p. But, for some reason, it didn't want to take 720p images\nsometimes! So I had to order a new one about half way through the experiment</p>\n<p>The <b style=\"color: green;\">green</b> dots correspond to images at 640x480 resolution and the <b style=\"color: red;\">red</b> dots correspond to images taken at 1280x720 resolution.</p>\n<p>Now if you haven't noticed, aside from the trendline upwards of green pixels over time, there is a major bump\nin the amount of green pixels identified from 480p to 720p to 1080p! This is because higher resolution images\ncan take more detailed images and can detect more green! I mean, you've probably always known that, but seeing\nit in graph form is even cooler. ðŸ†’</p>\n<p>But let me take a step back and actually show you how to extract the green pixels out of images.</p>\n<h2 id=\"organizetheimages\">Organize the images</h2>\n<p>First, let's just organize out images into the different categories. Right now, my data is just randomly arranged in a folder called <code>images</code> in the format of <code>unix_time_milliseconds.png</code>. I want to now organize them via their proper resolutions. See the code below:</p>\n<pre><code class=\"python language-python\">import os\nimport imagesize\n\ndef find_and_sort_images(directory):\n    image_files = os.listdir(directory)\n    image_files = list(filter(lambda f: f.endswith('.png'), image_files))\n    image_files = sorted(image_files)\n    image_files = [os.path.join(directory, f) for f in image_files]\n    return image_files\n\ndef groupby_resolution(images):\n    groups = {}\n    for file_name in images:\n        resolution = imagesize.get(file_name)\n        if resolution not in groups:\n            groups[resolution] = []\n        groups[resolution].append(file_name)\n    return groups\n\nimages = find_and_sort_images('./images')\ngroups = groupby_resolution(images)\n</code></pre>\n<p>Very cool! I am using this nice package here <a href=\"https://pypi.org/project/imagesize/\" alt=\"link\">imagesize==1.2.0</a> to parse the resolution from the image. This is a much faster way than using <code>cv2.imread().shape</code> to get the resolution because it only attempts to read the header of the png file.</p>\n<p>So what do I have as a data set after it's been grouped? Here are the results:</p>\n<pre><code>total images: 52656\nresolution (1920, 1080): 20555\nresolution (1280, 720): 26903\nresolution (640, 480): 4960\nresolution (-1, -1): 238\n</code></pre>\n<p>I have 52,656 images total overall. Over half of which are 480p and 720p. Only 20,555 images are 1080p. But, I also have 238 images that could not find the resolution at all! How could this happen?? Well upon inspecting the images, we find that these images are zero bytes in length. This is completely normal and expected to occur. Throughout my experience taking millions of images, the number one thing that seems to create this problem is insufficent voltage or a faulty camera.</p>\n<p>The Raspberry Pi 3B+ can only supply 1 AMP of current. Additionally, it recommends a 5 Volt 2.5 AMP power supply connected to a micro usb cable. Supplying this much current to the PI with a standard phone charger and cable will not cut it. You'll need a much stronger supply. If you don't, you will see kernel messages or a \"lightning bolt\" if your watching the display through HDMI saying that there is insufficent supply. This is definitely something to watch out for if your trying to power devices.</p>\n<p>To conclude, the best way to prevent this is to just supply a strong enough power supply, and add some checks in your code to prevent saving zero byte images.</p>\n<h2 id=\"extractthemask\">Extract the Mask</h2>\n<p>Moving onward, let's see the code that actually extracts the green pixels from an image of 1080p resolution.</p>\n<pre><code class=\"python language-python\">import cv2\n\ndef get_green_mask(image):\n    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n    lower_green = np.array([[55, 40, 40]])\n    upper_green = np.array([[80, 255, 255]])\n    mask = cv2.inRange(hsv, lower_green, upper_green)\n    return mask\n\ndef apply_green_filter(image, mask):\n    result = cv2.bitwise_and(image, image, mask=mask)\n    return result, mask\n\nfile_name = groups[(1920, 1080)][0]\nimage = cv2.imread(file_name)\nmask = get_green_mask(image)\nfiltered = apply_green_filter(image, mask)\n</code></pre>\n<p>So, we use the <code>imread()</code> function to read in an image. Next, we convert the color format from <code>RGB</code> to <code>HSV</code>. Instead of pixel information in the format of red, green, blue, we have hue, saturation, and brightness. Now, why would we want to do this?</p>\n<p>If we used RGB, we would be defining a range of how intense the reds, greens, and blues are in an image. But this isn't really sutable for our application becase we already know we want to capture only green and nothing else. What would be better is if we could define what color we want to capture, and then only capture green pixels of a certain brightness or saturation. Basically, of a certain range of \"discoloration\". And this is exactly what HSV does for us.</p>\n<p>First the <code>Hue</code>. The hue is just the base color. This information is encoded in a single byte from 0 to 255. I picked a range from 55 to 80 and it worked for my purposes. The best way to figure this out is simply to play around with the range. What I did is actually look at a few of my plant images and examine the leaf colors.</p>\n<p>The second is <code>Saturation</code>. Saturation is basically the \"colorfulness\" of the pixel. It defines just how much the color pops out at you. It's useful if you are trying to take those grams and you want to pretend that you live back in the 90's when cameras didn't have as much clarity. In our use case, it helps to define a comfortable range in case there are different lighting conditions or the color of green from the plants changes over time. I've defined 40 to 255 as my based range and it seems to work out nicely for me.</p>\n<p>The last is the <code>Lightness</code> or <code>Value</code> or <code>Brightness</code>. And it's exactly what it seems. It allows the pixel to define how intense the color is as if you were turning up the light or dimming it down. Again, very useful in our case as throughout the day the intensity of light changes. Again, I just threw a 40 to 255 range for this.</p>\n<p>Now that we know what HSV is, the next step is to run <code>cv2.inRange()</code> which will extract a mask of pixels containing only the pixel information we gave it. To actually see the result of the mask extracted from the image, we call <code>cv2.bitwise_and()</code> to compute the bitwise and operation over our original image and the mask. In plain english, that loops over the pixels of the image and only keeps the ones that exist within the mask.</p>\n<p>If we plot this information using matplotlib in the example below, we can see the results side by side:</p>\n<pre><code class=\"python language-python\">figure = plot.figure(figsize=(20, 5))\nfigure.add_subplot(1, 3, 1)\nplot.title('Original Image')\nplot.imshow(image)\nfigure.add_subplot(1, 3, 2)\nplot.title('Image Mask')\nplot.imshow(mask)\nfigure.add_subplot(1, 3, 3)\nplot.title('Filtered Image')\nplot.imshow(filtered)\n</code></pre>\n<p><details open>\n<summary>Image, Mask, Filtered Comparison</summary>\n<br>\n    <img src=\"https://www.speblog.org/image/autofarm/mask_comparison.png\">\n</details></p>\n<p>Oh we are really getting somewhere! Pretty dope right? Some masks are better than others as the lighting conditions change throughout the day. For whatever images and mask you have, play around with the color ranges. If your building a dataset, biasly pick a mask for each image that tries to capture the entire plant! (this is what I'm going to do in the future for instance segmentation).</p>\n<p>But we still have so many unanswered questions, like, how do I visualize all the green pixels over time? What if I just want to look at an individual plants and it's growth rate? What if I want to compare the plants growth rates over time?</p>\n<p>In the next blog, I will do just that. I hope you found something useful out of this blog. If you didn't, please describe how I can make it better in the comments below. For now, stay safe. Peace.</p>"
}